# ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨ ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶™‡ßç‡¶∞‡¶ú‡ßá‡¶ï‡ßç‡¶ü - ‡¶¨‡¶á ‡¶è‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π
"""
‡¶è‡¶á ‡¶™‡ßç‡¶∞‡¶ú‡ßá‡¶ï‡ßç‡¶ü‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ http://books.toscrape.com ‡¶•‡ßá‡¶ï‡ßá ‡¶¨‡¶á ‡¶è‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡¶¨‡ßã
‡¶è‡¶ü‡¶ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ü‡ßá‡¶∏‡ßç‡¶ü ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶∏‡¶æ‡¶á‡¶ü ‡¶Ø‡ßá‡¶ü‡¶ø ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶Ö‡¶®‡ßÅ‡¶∂‡ßÄ‡¶≤‡¶®‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶¨‡¶æ‡¶®‡¶æ‡¶®‡ßã ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import pdb


def scrape_books():
    """
    ‡¶¨‡¶á ‡¶è‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶™ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®
    """
    print("üöÄ ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶π‡¶ö‡ßç‡¶õ‡ßá...")
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36',
        'Accept-Language': 'en-US,en;q=0.9',
    }
    # ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶∏‡¶æ‡¶á‡¶ü‡ßá‡¶∞ URL
    url = "http://books.toscrape.com/"

    try:
        # ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶∏‡¶æ‡¶á‡¶ü‡ßá ‡¶∞‡¶ø‡¶ï‡ßÅ‡¶Ø‡¶º‡ßá‡¶∏‡ßç‡¶ü ‡¶™‡¶æ‡¶†‡¶æ‡¶®‡ßã
        print("üì° ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨‡¶∏‡¶æ‡¶á‡¶ü‡ßá ‡¶∏‡¶Ç‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá...")
        response = requests.get(url, headers=headers)

        # ‡¶∏‡¶Ç‡¶Ø‡ßã‡¶ó ‡¶∏‡¶´‡¶≤ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá ‡¶ï‡¶ø‡¶®‡¶æ ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶æ
        if response.status_code == 200:
            print("‚úÖ ‡¶∏‡¶Ç‡¶Ø‡ßã‡¶ó ‡¶∏‡¶´‡¶≤!")
        else:
            print(f"‚ùå ‡¶∏‡¶Ç‡¶Ø‡ßã‡¶ó ‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•! Status Code: {response.status_code}")
            return

        # HTML ‡¶ï‡ßã‡¶° ‡¶™‡¶æ‡¶∞‡ßç‡¶∏ ‡¶ï‡¶∞‡¶æ
        soup = BeautifulSoup(response.content, 'html.parser')

        # ‡¶¨‡¶á ‡¶è‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶≤‡¶ø‡¶∏‡ßç‡¶ü
        books_data = []

        # ‡¶∏‡¶¨ ‡¶¨‡¶á ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡¶æ
        books = soup.find_all('article', class_='product_pod')

        # print(f"üìö ‡¶Æ‡ßã‡¶ü {len(books)} ‡¶ü‡¶ø ‡¶¨‡¶á ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶ó‡ßá‡¶õ‡ßá!")

        # ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø ‡¶¨‡¶á ‡¶•‡ßá‡¶ï‡ßá ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡¶æ
        for i, book in enumerate(books, 1):
            try:
                # ‡¶¨‡¶á ‡¶è‡¶∞ ‡¶®‡¶æ‡¶Æ
                title = book.find('h3').find('a')['title']

                # ‡¶¨‡¶á ‡¶è‡¶∞ ‡¶¶‡¶æ‡¶Æ
                # price = book.find('p', class_='price_color').text
                price_tag = book.find("p", class_="price_color")
                price = price_tag.text if price_tag else "N/A"
                if price != "N/A":
                    price = price.strip(" ")  # ‡¶Ö‡¶§‡¶ø‡¶∞‡¶ø‡¶ï‡ßç‡¶§ ‡¶∏‡ßç‡¶™‡ßá‡¶∏ ‡¶∏‡¶∞‡¶æ‡¶á or remove "¬£"
                    # ‡¶Ø‡¶¶‡¶ø ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶ø‡¶Ç ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶•‡¶æ‡¶ï‡ßá, ‡¶§‡¶æ‡¶π‡¶≤‡ßá ¬£ ‡¶ö‡¶ø‡¶π‡ßç‡¶® ‡¶®‡¶ø‡¶∂‡ßç‡¶ö‡¶ø‡¶§ ‡¶ï‡¶∞‡¶ø
                    price = price.encode('utf-8').decode('utf-8')

                image_container = book.find("div", class_="image_container")
                if not image_container:
                    print(f"‡¶¨‡¶á '{title}' ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø image_container ‡¶™‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º‡¶®‡¶ø!")
                else:
                    # URL
                    # url_tag = image_container.find("a")["href"]
                    # print(f"URL: {base_url}{url_tag}")
                    # ============= or=====
                    url_tag = image_container.find("a")
                    book_url = url_tag["href"] if url_tag else "N/A"
                    full_book_url = url + book_url if book_url != "N/A" else "N/A"

                    # Image Path
                    img_tag = image_container.find("img")
                    image_path = img_tag["src"] if img_tag else "N/A"
                    full_image_url = url + image_path if image_path != "N/A" else "N/A"


                # ‡¶¨‡¶á ‡¶è‡¶∞ rating
                rating_classes = book.find('p', class_='star-rating')['class']
                rating = rating_classes[1]  # 'One', 'Two', 'Three', 'Four', 'Five'

                # ‡¶¨‡¶á ‡¶è‡¶∞ ‡¶∏‡ßç‡¶ü‡¶ï ‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶ü‡¶æ‡¶∏
                stock = book.find('p', class_='instock availability').text.strip()

                # ‡¶°‡¶ø‡¶ï‡¶∂‡¶®‡¶æ‡¶∞‡¶ø‡¶§‡ßá ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£
                book_info = {
                    'name': title,
                    'price': price,
                    'book_url': full_book_url,
                    'image': full_image_url,
                    'rating': rating,
                    'stock': stock
                }

                books_data.append(book_info)
                print(f"üìñ ‡¶¨‡¶á {i}: {title[:30]}...")

                # ‡¶∏‡¶æ‡¶∞‡ßç‡¶≠‡¶æ‡¶∞‡ßá ‡¶Ö‡¶§‡¶ø‡¶∞‡¶ø‡¶ï‡ßç‡¶§ ‡¶ö‡¶æ‡¶™ ‡¶®‡¶æ ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶¨‡¶ø‡¶∞‡¶§‡¶ø
                time.sleep(0.1)

            except Exception as e:
                print(f"‚ùå ‡¶¨‡¶á {i} ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ: {e}")
                continue

        return books_data

    except Exception as e:
        print(f"‚ùå ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶è ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ: {e}")
        return []


def save_to_csv(books_data, filename='books_data.csv'):
    """
    ‡¶¨‡¶á ‡¶è‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø CSV ‡¶´‡¶æ‡¶á‡¶≤‡ßá ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡¶æ
    """
    if books_data:
        df = pd.DataFrame(books_data)
        df.to_csv(filename, index=False, encoding="utf-8-sig")
        print(f"üíæ ‡¶§‡¶•‡ßç‡¶Ø '{filename}' ‡¶´‡¶æ‡¶á‡¶≤‡ßá ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶ø‡¶§ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá!")
        return True
    else:
        print("‚ùå ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶Æ‡¶§‡ßã ‡¶ï‡ßã‡¶®‡ßã ‡¶§‡¶•‡ßç‡¶Ø ‡¶®‡ßá‡¶á!")
        return False



def main():
    """
    ‡¶Æ‡ßÇ‡¶≤ ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®
    """
    print("üéØ ‡¶ì‡¶Ø‡¶º‡ßá‡¶¨ ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶™‡¶ø‡¶Ç ‡¶™‡ßç‡¶∞‡¶ú‡ßá‡¶ï‡ßç‡¶ü")
    print("=" * 50)

    # ‡¶¨‡¶á ‡¶è‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡ßç‡¶ï‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶™ ‡¶ï‡¶∞‡¶æ
    books_data = scrape_books()

    if books_data:
        print(f"\nüéâ ‡¶∏‡¶´‡¶≤‡¶≠‡¶æ‡¶¨‡ßá {len(books_data)} ‡¶ü‡¶ø ‡¶¨‡¶á ‡¶è‡¶∞ ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡¶æ ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá!")


        # CSV ‡¶´‡¶æ‡¶á‡¶≤‡ßá ‡¶∏‡¶Ç‡¶∞‡¶ï‡ßç‡¶∑‡¶£ ‡¶ï‡¶∞‡¶æ
        save_to_csv(books_data)

        # ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶™‡¶∞‡¶ø‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ‡¶® ‡¶¶‡ßá‡¶ñ‡¶æ‡¶®‡ßã
        print("\nüìä ‡¶™‡¶∞‡¶ø‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ‡¶®:")
        print(f"   ‡¶Æ‡ßã‡¶ü ‡¶¨‡¶á: {len(books_data)}")

        # price‡ßá‡¶∞ ‡¶≠‡¶ø‡¶§‡ßç‡¶§‡¶ø‡¶§‡ßá ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£
        prices = [float(book['price'][1:]) for book in books_data]  # ¬£ ‡¶ö‡¶ø‡¶π‡ßç‡¶® ‡¶¨‡¶æ‡¶¶ ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá
        print(f"   ‡¶∏‡¶∞‡ßç‡¶¨‡ßã‡¶ö‡ßç‡¶ö price: ¬£{max(prices):.2f}")
        print(f"   ‡¶∏‡¶∞‡ßç‡¶¨‡¶®‡¶ø‡¶Æ‡ßç‡¶® price: ¬£{min(prices):.2f}")
        print(f"   ‡¶ó‡¶°‡¶º price: ¬£{sum(prices) / len(prices):.2f}")

    else:
        print("‚ùå ‡¶ï‡ßã‡¶®‡ßã ‡¶§‡¶•‡ßç‡¶Ø ‡¶∏‡¶Ç‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º‡¶®‡¶ø!")


# ‡¶™‡ßç‡¶∞‡¶Ø‡¶º‡ßã‡¶ú‡¶®‡ßÄ‡¶Ø‡¶º ‡¶≤‡¶æ‡¶á‡¶¨‡ßç‡¶∞‡ßá‡¶∞‡¶ø ‡¶á‡¶®‡¶∏‡ßç‡¶ü‡¶≤ ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ï‡¶Æ‡¶æ‡¶®‡ßç‡¶°:
"""
pip install requests beautifulsoup4 pandas
"""

if __name__ == "__main__":
    main()